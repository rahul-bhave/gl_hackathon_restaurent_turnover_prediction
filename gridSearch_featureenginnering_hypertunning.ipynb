{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fc4daa1-375a-4dda-8bbc-4a491ddba3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'c:\\users\\rahulbhave\\code\\gl_hackathon_restaurent_turnover_prediction\\env\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\rahulbhave\\code\\gl_hackathon_restaurent_turnover_prediction\\env\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\rahulbhave\\code\\gl_hackathon_restaurent_turnover_prediction\\env\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: xgboost in c:\\users\\rahulbhave\\code\\gl_hackathon_restaurent_turnover_prediction\\env\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rahulbhave\\code\\gl_hackathon_restaurent_turnover_prediction\\env\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rahulbhave\\code\\gl_hackathon_restaurent_turnover_prediction\\env\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rahulbhave\\code\\gl_hackathon_restaurent_turnover_prediction\\env\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\rahulbhave\\code\\gl_hackathon_restaurent_turnover_prediction\\env\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rahulbhave\\code\\gl_hackathon_restaurent_turnover_prediction\\env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\rahulbhave\\code\\gl_hackathon_restaurent_turnover_prediction\\env\\lib\\site-packages (from scikit-learn) (3.4.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\rahulbhave\\code\\gl_hackathon_restaurent_turnover_prediction\\env\\lib\\site-packages (from scikit-learn) (1.13.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\rahulbhave\\code\\gl_hackathon_restaurent_turnover_prediction\\env\\lib\\site-packages (from scikit-learn) (1.4.0)\n",
      "Index(['Registration Number', 'Facebook Popularity Quotient',\n",
      "       'Instagram Popularity Quotient', 'Fire Audit',\n",
      "       'Liquor License Obtained', 'Situated in a Multi Complex',\n",
      "       'Dedicated Parking', 'Open Sitting Available', 'Resturant Tier',\n",
      "       'Restaurant Zomato Rating',\n",
      "       ...\n",
      "       'Restaurant Theme_Parsi', 'Restaurant Theme_Petit',\n",
      "       'Restaurant Theme_Picante', 'Restaurant Theme_Piquant',\n",
      "       'Restaurant Theme_Resca', 'Restaurant Theme_Sage',\n",
      "       'Restaurant Theme_Savory', 'Restaurant Theme_Spoon',\n",
      "       'Restaurant Theme_TheGem', 'Restaurant Theme_Umami'],\n",
      "      dtype='object', length=1847)\n",
      "Columns of X_val before transformation: Index(['Registration Number', 'Facebook Popularity Quotient',\n",
      "       'Instagram Popularity Quotient', 'Fire Audit',\n",
      "       'Liquor License Obtained', 'Situated in a Multi Complex',\n",
      "       'Dedicated Parking', 'Open Sitting Available', 'Resturant Tier',\n",
      "       'Restaurant Zomato Rating',\n",
      "       ...\n",
      "       'Restaurant Theme_Petit', 'Restaurant Theme_Picante',\n",
      "       'Restaurant Theme_Piquant', 'Restaurant Theme_Resca',\n",
      "       'Restaurant Theme_Sage', 'Restaurant Theme_Savory',\n",
      "       'Restaurant Theme_Spoon', 'Restaurant Theme_TheGem',\n",
      "       'Restaurant Theme_Umami', 'Interaction_Feature'],\n",
      "      dtype='object', length=1848)\n",
      "Columns of X_val after transformation: 10\n",
      "Ensemble Model Validation RMSE: 21264036.201737117\n",
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "[CV] END ..learning_rate=0.05, max_depth=3, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.05, max_depth=3, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.05, max_depth=3, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.05, max_depth=3, n_estimators=200; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.05, max_depth=3, n_estimators=200; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.05, max_depth=3, n_estimators=200; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.05, max_depth=3, n_estimators=300; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.05, max_depth=3, n_estimators=300; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.05, max_depth=3, n_estimators=300; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.05, max_depth=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.05, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.05, max_depth=4, n_estimators=200; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.05, max_depth=4, n_estimators=200; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.05, max_depth=4, n_estimators=200; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.05, max_depth=4, n_estimators=300; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.05, max_depth=4, n_estimators=300; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.05, max_depth=4, n_estimators=300; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.05, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.05, max_depth=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.05, max_depth=5, n_estimators=200; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.05, max_depth=5, n_estimators=300; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.05, max_depth=5, n_estimators=300; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.05, max_depth=5, n_estimators=300; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=300; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=300; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=300; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=300; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=300; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=300; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=3, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=3, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=3, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=3, n_estimators=300; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.2, max_depth=3, n_estimators=300; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.2, max_depth=3, n_estimators=300; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=200; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=200; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=200; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=300; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=300; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=300; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=5, n_estimators=200; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.2, max_depth=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=5, n_estimators=300; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.2, max_depth=5, n_estimators=300; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.2, max_depth=5, n_estimators=300; total time=   0.4s\n",
      "Train RMSE with best parameters: 17082461.97643516\n",
      "Validation RMSE with best parameters: 21202911.61555194\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Installing necessary libraries\n",
    "!pip install pandas scikit-learn xgboost\n",
    "\n",
    "# Step 2: Import required libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from xgboost import XGBRegressor\n",
    "import numpy as np\n",
    "\n",
    "# Step 3: Load the data\n",
    "train_data = pd.read_csv('Train_dataset.csv')\n",
    "test_data = pd.read_csv('Test_dataset.csv')\n",
    "\n",
    "# Step 4: Data Preprocessing\n",
    "X = train_data.drop(columns=['Annual Turnover'])\n",
    "y = train_data['Annual Turnover']\n",
    "X_test = test_data.drop(columns=['Registration Number'])\n",
    "\n",
    "# Drop non-important columns if they exist\n",
    "X = X.drop(columns=['City', 'Cuisine'], errors='ignore')\n",
    "X_test = X_test.drop(columns=['City', 'Cuisine'], errors='ignore')\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "X = pd.get_dummies(X)\n",
    "X_test = pd.get_dummies(X_test)\n",
    "\n",
    "# Align the columns of training and test datasets\n",
    "X, X_test = X.align(X_test, join='left', axis=1, fill_value=0)\n",
    "\n",
    "# Step 5: Splitting the Data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 6: Impute missing values only for numeric columns\n",
    "numeric_cols = X_train.select_dtypes(include=['number']).columns\n",
    "numeric_cols = numeric_cols.drop('Registration Number', errors='ignore')\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train[numeric_cols] = imputer.fit_transform(X_train[numeric_cols])\n",
    "X_val[numeric_cols] = imputer.transform(X_val[numeric_cols])\n",
    "X_test[numeric_cols] = imputer.transform(X_test[numeric_cols])\n",
    "\n",
    "# Feature Engineering\n",
    "# Create interaction features\n",
    "print(X_train.columns)\n",
    "X_train['Interaction_Feature'] = X_train['Registration Number'] * X_train['Overall Restaurant Rating']\n",
    "\n",
    "# Feature Selection\n",
    "# Example: Select top k most important features\n",
    "# Fit a Gradient Boosting model\n",
    "gb_reg = GradientBoostingRegressor(random_state=42)\n",
    "gb_reg.fit(X_train, y_train)\n",
    "\n",
    "# Select top 10 most important features\n",
    "selector = SelectFromModel(gb_reg, max_features=10)\n",
    "selector.fit(X_train, y_train)\n",
    "\n",
    "# Transform the data\n",
    "X_train_selected = selector.transform(X_train)\n",
    "\n",
    "# Include 'Interaction_Feature' in the columns of X_val\n",
    "X_val['Interaction_Feature'] = X_val['Registration Number'] * X_val['Overall Restaurant Rating']\n",
    "\n",
    "# Check the columns of the validation set\n",
    "print(\"Columns of X_val before transformation:\", X_val.columns)\n",
    "\n",
    "# Transform the validation set\n",
    "X_val_selected = selector.transform(X_val)\n",
    "\n",
    "# Print the columns of the transformed validation set\n",
    "print(\"Columns of X_val after transformation:\", X_val_selected.shape[1])\n",
    "\n",
    "# Model Ensemble\n",
    "# Initialize individual models\n",
    "rf_reg = RandomForestRegressor(random_state=42)\n",
    "xgb_reg = XGBRegressor(random_state=42)\n",
    "\n",
    "# Train individual models\n",
    "rf_reg.fit(X_train, y_train)\n",
    "xgb_reg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "rf_preds = rf_reg.predict(X_val)\n",
    "xgb_preds = xgb_reg.predict(X_val)\n",
    "\n",
    "# Combine predictions (simple averaging)\n",
    "ensemble_preds = (rf_preds + xgb_preds) / 2\n",
    "\n",
    "# Evaluate ensemble model\n",
    "ensemble_rmse = np.sqrt(mean_squared_error(y_val, ensemble_preds))\n",
    "print(\"Ensemble Model Validation RMSE:\", ensemble_rmse)\n",
    "\n",
    "# Step 7: Model Building - Gradient Boosting Regression with Hyperparameter Tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "\n",
    "gb_reg = GradientBoostingRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(estimator=gb_reg, param_grid=param_grid, cv=3, scoring='neg_root_mean_squared_error', verbose=2)\n",
    "grid_search.fit(X_train_selected, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "gb_reg_best = GradientBoostingRegressor(**best_params, random_state=42)\n",
    "gb_reg_best.fit(X_train_selected, y_train)\n",
    "\n",
    "# Step 8: Model Evaluation\n",
    "train_predictions_best = gb_reg_best.predict(X_train_selected)\n",
    "val_predictions_best = gb_reg_best.predict(X_val_selected)\n",
    "\n",
    "train_rmse_best = np.sqrt(mean_squared_error(y_train, train_predictions_best))\n",
    "val_rmse_best = np.sqrt(mean_squared_error(y_val, val_predictions_best))\n",
    "\n",
    "print(\"Train RMSE with best parameters:\", train_rmse_best)\n",
    "print(\"Validation RMSE with best parameters:\", val_rmse_best)\n",
    "\n",
    "if 'Interaction_Feature' not in X_test.columns:\n",
    "    X_test['Interaction_Feature'] = X_test['Registration Number'] * X_test['Overall Restaurant Rating']\n",
    "\n",
    "# Transform the test data using the same feature selection\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# Step 9: Making Predictions\n",
    "test_predictions_best = gb_reg_best.predict(X_test_selected)\n",
    "\n",
    "# Step 10: Creating Submission File\n",
    "submission_df = pd.DataFrame({'Registration Number': test_data['Registration Number'], 'Annual Turnover': test_predictions_best})\n",
    "submission_df.to_csv('submission_greadsearch_featureenginnering_hypertunning.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b758523-2415-426d-92c5-a6e4c801a31e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
